services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports: ["2181:2181"]

  kafka:
    image: confluentinc/cp-kafka:7.5.3
    depends_on: [zookeeper]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

      # Define both listeners explicitly (internal + host)
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      # Single-broker dev settings
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

      KAFKA_LOG_RETENTION_BYTES: 134217728   # 128 MB total per topic
      KAFKA_LOG_RETENTION_MS: 3600000        # 1 hour retention
      KAFKA_LOG_SEGMENT_BYTES: 67108864      # 64 MB segments
      KAFKA_DELETE_TOPIC_ENABLE: "true"


      # Optional but helpful in dev
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

    ports:
      - "9093:9093"     # host access (external)
    healthcheck:
      test: ["CMD", "bash", "-lc", "kafka-broker-api-versions --bootstrap-server localhost:9092 >/dev/null 2>&1"]
      interval: 10s
      timeout: 5s
      retries: 20


  redis:
    image: redis:7
    ports: 
      - "6379:6379"
    healthcheck:
      #test: ["CMD", "redis-cli", "ping"]
      test: ["CMD-SHELL", "redis-cli ping || exit 1"]
      interval: 5s
      timeout: 3s
      retries: 30

  neo4j:
    image: neo4j:5.23.0
    ports:
      - "7474:7474"   # HTTP (browser)
      - "7687:7687"   # Bolt
    environment:
      - NEO4J_AUTH=neo4j/testpassword
      - NEO4J_server_memory_heap_initial__size=512m
      - NEO4J_server_memory_heap_max__size=512m
      - NEO4J_server_memory_pagecache_size=256m
      
    volumes:
      - neo4j_data:/data
    healthcheck:
      test: ["CMD-SHELL", "cypher-shell -u neo4j -p testpassword 'RETURN 1' | grep -q 1"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 20s
  
  
  
  
  graph-writer:
    build:
      context: .
      dockerfile: apps/graph_writer/Dockerfile
    environment:
      - PYTHONPATH=/app
      - KAFKA_BOOTSTRAP=${KAFKA_BOOTSTRAP:-kafka:9092}
      - ENRICHED_TOPIC=${ENRICHED_TOPIC:-enriched-documents}
      - NEO4J_URI=${NEO4J_URI:-bolt://neo4j:7687}
      - NEO4J_USER=${NEO4J_USER:-neo4j}
      - NEO4J_PASS=${NEO4J_PASS:-testpassword}
      - BATCH_MAX_DOCS=200
      - BATCH_FLUSH_SEC=3
    depends_on:
      kafka:
        condition: service_healthy
      neo4j:
        condition: service_healthy
    
    restart: unless-stopped
  

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.14.2
    #container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - indices.query.bool.max_clause_count=4096
    ports: ["9200:9200"]
    volumes:
      - esdata:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:9200/_cluster/health | grep -q '\"status\"'"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 10s
    restart: unless-stopped

  kibana:
    image: docker.elastic.co/kibana/kibana:8.14.2
    depends_on: 
      elasticsearch:
        condition: service_healthy
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - SERVER_NAME=kibana
    ports: ["5601:5601"]
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:5601/api/status | grep -q 'overall'"]
      interval: 15s
      timeout: 5s
      retries: 40
      start_period: 15s

  api:
    build:
      context: .
      dockerfile: apps/api/Dockerfile
    environment:
      - NEO4J_URI=${NEO4J_URI:-bolt://neo4j:7687}
      - NEO4J_USER=${NEO4J_USER:-neo4j}
      - NEO4J_PASS=${NEO4J_PASS:-testpassword}
      - NEO4J_ENABLED=${NEO4J_ENABLED:-1}
      - ELASTIC_URL=${ELASTIC_URL:-http://elasticsearch:9200}
      - ES_INDEX_ALIAS=${ES_INDEX_ALIAS:-news-enriched}
      - REDIS_URL=${REDIS_URL}
      - KAFKA_BOOTSTRAP=${KAFKA_BOOTSTRAP}      
      - MIN_CITATIONS=${MIN_CITATIONS:-3}
      - MAX_TOKENS=${MAX_TOKENS:-8192}
      - PYTHONPATH=/app
    depends_on: [neo4j, elasticsearch, redis, kafka]
    ports: ["8080:8000"]
    command: ["uvicorn", "apps.api.main:app", "--host", "0.0.0.0", "--port", "8080"]
    restart: unless-stopped

  ingest:
    build:
      context: .
      dockerfile: apps/ingest/Dockerfile
    environment:
      - KAFKA_BOOTSTRAP=${KAFKA_BOOTSTRAP:-kafka:9092}
      - RAW_TOPIC=${RAW_TOPIC:-raw-documents}
      - INGEST_INTERVAL_SEC=600
      - USE_STUB_FEEDS=0
      - RSS_FEEDS=https://feeds.bbci.co.uk/news/rss.xml,https://www.theverge.com/rss/index.xml,https://feeds.arstechnica.com/arstechnica/index/,http://feeds.feedburner.com/TechCrunch/
      - RSS_FEEDS_FILE=/app/feeds.txt
    depends_on: 
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./feeds/feeds.txt:/app/feeds.txt:ro
    restart: unless-stopped

  enricher:
    build:
      context: .
      dockerfile: apps/enricher/Dockerfile
    environment:
      - PYTHONPATH=/app
      - KAFKA_BOOTSTRAP=${KAFKA_BOOTSTRAP:-kafka:9092}
      - RAW_TOPIC=${RAW_TOPIC:-raw-documents}
      - ENRICHED_TOPIC=${ENRICHED_TOPIC:-enriched-documents}
      - ERROR_TOPIC=${ERROR_TOPIC:-errors-documents}
      - GROUP_ID=${GROUP_ID:-enricher.v1}
      - SPACY_MODEL=en_core_web_sm
      - ALLOW_RUNTIME_MODEL_DOWNLOAD=0
    depends_on:
      kafka:
        condition: service_healthy
    
    restart: unless-stopped
  
  indexer:
    build:
      context: .
      dockerfile: apps/indexer/Dockerfile
      
    depends_on:
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    environment:
      - PYTHONPATH=/app
      - KAFKA_BOOTSTRAP=${KAFKA_BOOTSTRAP:-kafka:9092}
      - ENRICHED_TOPIC=${ENRICHED_TOPIC:-enriched-documents}
      - ELASTIC_URL=${ELASTIC_URL:-http://elasticsearch:9200}
      - ES_INDEX_ALIAS=${ES_INDEX_ALIAS:-news-enriched}
      - ES_INDEX=${ES_INDEX:-news-enriched-v1}
      - ES_SHARDS=1
      - ES_REPLICAS=0
      - BATCH_MAX_DOCS=500
      - BATCH_FLUSH_SEC=3
    restart: unless-stopped

  
  
  orchestrator:
    build:
      context: .
      dockerfile: apps/orchestrator/Dockerfile
    environment:
      - REDIS_URL=${REDIS_URL}
      - COST_CAP_USD=${COST_CAP_USD:-2.00}
    depends_on: [api, redis]



volumes:
  neo4j_data:
  esdata:
  


